<p align="center">
  <img src="https://raw.githubusercontent.com/sharvinzlife/OpenClaw-On-Pi/main/assets/logo.png" alt="OpenClaw Logo" width="200"/>
</p>

<h1 align="center">ğŸ¤– OpenClaw-On-Pi</h1>

<p align="center">
  <strong>AI-Powered Telegram Bot with Multi-Provider LLM Support</strong><br>
  <em>Designed & Optimized for Raspberry Pi</em>
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-commands">Commands</a> â€¢
  <a href="#-dashboard">Dashboard</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Version-0.3.0-orange?style=for-the-badge" alt="Version"/>
  <img src="https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License"/>
  <img src="https://img.shields.io/badge/Platform-Raspberry%20Pi-C51A4A?style=for-the-badge&logo=raspberrypi&logoColor=white" alt="Platform"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Telegram-Bot-26A5E4?style=flat-square&logo=telegram&logoColor=white" alt="Telegram"/>
  <img src="https://img.shields.io/badge/Groq-LLM-FF6B35?style=flat-square" alt="Groq"/>
  <img src="https://img.shields.io/badge/Ollama_Cloud-â˜ï¸-10B981?style=flat-square" alt="Ollama Cloud"/>
  <img src="https://img.shields.io/badge/Ollama-Local%20AI-000000?style=flat-square" alt="Ollama"/>
  <img src="https://img.shields.io/badge/Flask-Dashboard-000000?style=flat-square&logo=flask&logoColor=white" alt="Flask"/>
</p>

---

## ğŸŒŸ What is OpenClaw?

OpenClaw is a **production-ready AI chatbot** that runs on your Raspberry Pi and connects to Telegram. It intelligently routes requests between multiple LLM providers (Groq, Ollama Cloud, Local Ollama) with automatic failover, rate limiting, and a beautiful web dashboard for monitoring.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ Your Raspberry Pi                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Telegram  â”‚â”€â”€â”€â–¶â”‚  OpenClaw   â”‚â”€â”€â”€â–¶â”‚  Dashboard  â”‚         â”‚
â”‚  â”‚     Bot     â”‚    â”‚   Engine    â”‚    â”‚   :8080     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            â”‚                                    â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚         â–¼                  â–¼                  â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚    Groq    â”‚    â”‚   Ollama    â”‚    â”‚   Local     â”‚         â”‚
â”‚  â”‚  (Primary)  â”‚    â”‚   Cloud     â”‚    â”‚   Ollama    â”‚         â”‚
â”‚  â”‚     âš¡      â”‚    â”‚     â˜ï¸      â”‚    â”‚     ğŸ–¥ï¸      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **Multi-Provider AI** | Groq (blazing fast), Ollama Cloud (18+ models), Local Ollama (privacy) |
| ğŸ”„ **Smart Failover** | Automatic switching on rate limits or errors |
| âš¡ **Rate Limiting** | Sliding window algorithm with proactive failover at 80% |
| ğŸ” **Permission System** | Admin, User, Guest roles with granular access |
| ğŸ’¬ **Context Memory** | Persistent conversations with token-aware truncation |
| ğŸ“Š **Web Dashboard** | Beautiful glassy ivory-orange monitoring UI |
| ğŸ“ **Audit Logging** | Complete activity tracking with PII redaction |
| ğŸ¨ **Professional CLI** | Colorful interface with emojis |
| ğŸ§ª **50 Property Tests** | Comprehensive test coverage with Hypothesis |

---

## ğŸš€ Quick Start

### Prerequisites

- ğŸ“ Raspberry Pi (any model with Python 3.9+)
- ğŸ“± Telegram account
- ğŸ”‘ Groq API key (free at [console.groq.com](https://console.groq.com))

### One-Command Setup (Recommended)

```bash
# Clone the repository
git clone https://github.com/sharvinzlife/OpenClaw-On-Pi.git
cd OpenClaw-On-Pi

# Run setup â€” installs uv, dependencies, and launches the CLI wizard
./setup
```

The setup wizard will guide you through configuring API keys with a menu-based selector:

```
  ğŸ”‘ Configure API Keys
  
  Which key would you like to configure?
  
  [1] ğŸ¤– Telegram Bot Token     (Get from @BotFather)
  [2] âš¡ Groq API Key            (Get from console.groq.com)
  [3] â˜ï¸  Ollama Cloud API Key    (Get from ollama.com/account)
  [4] ğŸ”™ Back to main menu
```

### Management Scripts

```bash
./start     # Start the bot (foreground)
./stop      # Stop the running bot
./restart   # Restart the bot
./setup     # Re-run setup wizard
```

### Manual Installation

```bash
# 1. Clone
git clone https://github.com/sharvinzlife/OpenClaw-On-Pi.git
cd OpenClaw-On-Pi

# 2. Install uv (Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 3. Install dependencies
uv sync

# 4. Configure API keys via CLI wizard
uv run python -m src.cli

# 5. Add yourself as admin
nano config/permissions.yaml  # Add your Telegram user ID

# 6. Start
./start
```

---

## ğŸ—ï¸ Architecture


```mermaid
flowchart TB
    subgraph External["â˜ï¸ External Services"]
        TG[("ğŸ“± Telegram API")]
        GROQ[("âš¡ Groq API")]
        OLLAMA_CLOUD[("â˜ï¸ Ollama Cloud")]
    end

    subgraph Pi["ğŸ“ Raspberry Pi"]
        subgraph Bot["ğŸ¤– Telegram Bot"]
            TH["TelegramHandler"]
            CR["CommandRouter"]
        end

        subgraph LLM["ğŸ§  LLM Layer"]
            PM["ProviderManager"]
            RL["RateLimiter"]
            GP["GroqProvider"]
            OCP["OllamaCloudProvider"]
            OLP["LocalOllamaProvider"]
        end

        subgraph Security["ğŸ” Security"]
            AM["AuthManager"]
            AL["AuditLogger"]
        end

        subgraph Storage["ğŸ’¾ Storage"]
            CM["ConfigManager"]
            CS["ContextStore"]
        end

        subgraph Web["ğŸŒ Dashboard"]
            DASH["Flask App :8080"]
            DS["DashboardState"]
        end
    end

    TG <--> TH
    TH --> CR
    CR --> PM
    CR --> AM
    PM --> RL
    PM --> GP
    PM --> OCP
    PM --> OLP
    GP --> GROQ
    OCP --> OLLAMA_CLOUD
    AM --> AL
    CR --> CS
    TH --> DS
    DS --> DASH

    style Pi fill:#FFF5E6,stroke:#FF6B35,stroke-width:2px
    style Bot fill:#E3F2FD,stroke:#2196F3,stroke-width:1px
    style LLM fill:#F3E5F5,stroke:#9C27B0,stroke-width:1px
    style Security fill:#FFEBEE,stroke:#F44336,stroke-width:1px
    style Storage fill:#E8F5E9,stroke:#4CAF50,stroke-width:1px
    style Web fill:#FFF8E1,stroke:#FF9800,stroke-width:1px
```

### ğŸ“¦ Module Structure

```mermaid
graph LR
    subgraph src["ğŸ“ src/"]
        bot["ğŸ¤– bot/"]
        llm["ğŸ§  llm/"]
        security["ğŸ” security/"]
        utils["ğŸ”§ utils/"]
        web["ğŸŒ web/"]
    end

    bot --> |"command_router.py"| CR2["16 Commands"]
    bot --> |"telegram_handler.py"| TH2["Streaming Responses"]
    
    llm --> |"provider_manager.py"| PM2["Failover Logic"]
    llm --> |"rate_limiter.py"| RL2["Sliding Window"]
    llm --> |"*_provider.py"| PROV["3 Providers"]
    
    security --> |"auth.py"| AUTH["Permissions + Lockout"]
    
    utils --> |"config_manager.py"| CFG["YAML + ENV"]
    utils --> |"context_store.py"| CTX["Persistence"]
    utils --> |"audit_logger.py"| AUD["PII Redaction"]
    
    web --> |"dashboard.py"| DASH2["Real-time UI"]
```

---

## âš™ï¸ Configuration

### ğŸ”‘ API Keys (`config/.env`)

```env
# Required
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather
GROQ_API_KEY=your_groq_api_key

# Optional â€” Ollama Cloud (access 18+ cloud models)
OLLAMA_API_KEY=your_ollama_cloud_api_key
```

### ğŸ‘¤ Get Your Telegram User ID

1. Message [@userinfobot](https://t.me/userinfobot) on Telegram
2. Copy your user ID
3. Add to `config/permissions.yaml`:

```yaml
admins:
  - 123456789  # Your user ID here
```

---

## ğŸ® CLI Commands

```bash
./setup              # ğŸ”§ First-time setup wizard
./start              # ğŸš€ Start the bot
./stop               # ğŸ›‘ Stop the bot
./restart            # ğŸ”„ Restart the bot
```

### CLI Preview

```
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•—
  â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•
   â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•šâ•â•â•

                    AI-Powered Telegram Bot
        ğŸ§  Groq  â˜ï¸ Ollama Cloud  ğŸ–¥ï¸ Local Ollama

  What would you like to do?

  [1] ğŸš€ Start the bot
  [2] ğŸ”‘ Configure API keys
  [3] ğŸ”’ Edit permissions
  [4] âš™ï¸ Check status
  [5] âœ… Run tests
  [6] ğŸ”— Start dashboard only
  [q] Quit
```

---

## ğŸ¤– Telegram Commands


### ğŸ‘¤ Guest Commands
| Command | Description |
|---------|-------------|
| `/start` | ğŸ‘‹ Welcome message and quick start guide |
| `/help` | ğŸ“š Show available commands for your role |

### ğŸ‘¥ User Commands
| Command | Description |
|---------|-------------|
| `/status` | ğŸ“Š Bot status and current provider |
| `/provider` | ğŸ§  Show active AI provider details |
| `/switch <name>` | ğŸ”„ Switch to different AI provider |
| `/models` | ğŸ“‹ List available AI models |
| `/reset` | ğŸ—‘ï¸ Clear your conversation history |
| `/quota` | ğŸ“ˆ Check your rate limit status |

### ğŸ‘‘ Admin Commands
| Command | Description |
|---------|-------------|
| `/stats` | ğŸ“Š Global usage statistics |
| `/users` | ğŸ‘¥ List all active users |
| `/broadcast <msg>` | ğŸ“¢ Send message to all users |
| `/reload` | ğŸ”„ Reload configuration files |
| `/audit [n]` | ğŸ“ View last n audit log entries |
| `/health` | ğŸ¥ System health check |
| `/ban <id>` | ğŸš« Ban a user |
| `/unban <id>` | âœ… Unban a user |

---

## ğŸ“Š Web Dashboard

Access the monitoring dashboard at `http://your-pi-ip:8080`

### Features

- ğŸŸ¢ **Real-time Status** - Bot online/offline indicator
- â±ï¸ **Uptime Counter** - How long the bot has been running
- ğŸ’¬ **Message Counter** - Total messages processed
- ğŸ¯ **Token Usage** - Tokens consumed across providers
- ğŸ‘¥ **Active Users** - Currently active user count
- ğŸ§  **Provider Status** - Health of each AI provider with active toggle
- ğŸ”„ **Model Switching** - Change AI models per provider from the UI
- ğŸ“Š **Rate Limits** - Visual progress bars for limits
- ğŸ“ **Activity Feed** - Recent bot activity stream

### Design

Beautiful **glassy ivory-orange** design with:
- Animated floating orbs background
- Glassmorphism panels
- Responsive layout for mobile
- Auto-refresh every 5 seconds

---

## â˜ï¸ Ollama Cloud Models

OpenClaw supports 18+ cloud models via [Ollama Cloud](https://ollama.com), including:

| Model | Size | Best For |
|-------|------|----------|
| DeepSeek V3.2 | 671B | General reasoning (default) |
| GLM-5 | - | Chinese + English tasks |
| GLM-4.7 Flash | - | Fast Chinese + English |
| Kimi K2.5 | - | Long context reasoning |
| Cogito 2.1 | 671B | Deep thinking |
| Mistral Large 3 | 675B | Multilingual, code |
| Qwen3 Coder | 480B | Code generation |
| Qwen3 Coder Next | - | Latest code model |
| GPT-OSS | 120B | General purpose |
| Gemma 3 | 27B | Lightweight tasks |
| LFM 2.5 Thinking | - | Reasoning |

Switch models from the web dashboard or via Telegram commands.

---

## ğŸ“ Raspberry Pi Compatibility

| Model | Architecture | Status |
|-------|--------------|--------|
| Pi 5 | ARM64 | âœ… Tested |
| Pi 4 | ARM64 | âœ… Tested |
| Pi 3 | ARM64/ARM32 | âœ… Compatible |
| Pi Zero 2 W | ARM64 | âœ… Compatible |
| Pi Zero W | ARM32 | âš ï¸ Limited (no local Ollama) |

### Supported Operating Systems

- ğŸ¥§ **DietPi** (Recommended - lightweight)
- ğŸ“ **Raspberry Pi OS** (64-bit or 32-bit)
- ğŸ§ **Ubuntu Server** (ARM64)
- ğŸ§ **Debian** (ARM64)

---

## ğŸ§ª Testing

OpenClaw includes **50 property-based tests** using [Hypothesis](https://hypothesis.readthedocs.io/).

```bash
# Run all tests
./start test

# Or with pytest directly
.venv/bin/python -m pytest tests/ -v

# Run specific test file
.venv/bin/python -m pytest tests/property/test_auth_properties.py -v
```

### Test Coverage

```mermaid
pie title Test Distribution
    "Authentication" : 9
    "Rate Limiting" : 9
    "Provider Routing" : 9
    "Context Management" : 7
    "Configuration" : 3
    "Audit Logging" : 8
    "Command Routing" : 5
```

| Module | Tests | Coverage |
|--------|-------|----------|
| ğŸ” Authentication | 9 | Allowlist, lockout, hierarchy |
| âš¡ Rate Limiting | 9 | Sliding window, failover threshold |
| ğŸ§  Provider Routing | 9 | Priority, failover, recovery |
| ğŸ’¬ Context Store | 7 | Isolation, truncation, persistence |
| âš™ï¸ Configuration | 3 | Loading, validation |
| ğŸ“ Audit Logging | 8 | Completeness, PII redaction |
| ğŸ® Commands | 5 | Permission filtering |

---

## ğŸ“ Project Structure

```
OpenClaw-On-Pi/
â”œâ”€â”€ ğŸ“ config/                    # Configuration files
â”‚   â”œâ”€â”€ .env.template            # API keys template
â”‚   â”œâ”€â”€ config.yaml              # App settings
â”‚   â”œâ”€â”€ providers.yaml           # LLM provider config
â”‚   â””â”€â”€ permissions.yaml         # User permissions
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Source code
â”‚   â”œâ”€â”€ ğŸ“ bot/                   # Telegram bot
â”‚   â”‚   â”œâ”€â”€ command_router.py    # 16 commands
â”‚   â”‚   â””â”€â”€ telegram_handler.py  # Message handling
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ llm/                   # LLM providers
â”‚   â”‚   â”œâ”€â”€ base_provider.py     # Abstract base
â”‚   â”‚   â”œâ”€â”€ groq_provider.py     # Groq integration
â”‚   â”‚   â”œâ”€â”€ ollama_cloud_provider.py
â”‚   â”‚   â”œâ”€â”€ ollama_local_provider.py
â”‚   â”‚   â”œâ”€â”€ provider_manager.py  # Failover logic
â”‚   â”‚   â””â”€â”€ rate_limiter.py      # Sliding window
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ security/              # Security
â”‚   â”‚   â””â”€â”€ auth.py              # Permissions + lockout
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/                 # Utilities
â”‚   â”‚   â”œâ”€â”€ config_manager.py    # YAML + ENV loading
â”‚   â”‚   â”œâ”€â”€ context_store.py     # Conversation memory
â”‚   â”‚   â””â”€â”€ audit_logger.py      # Activity logging
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ web/                   # Dashboard
â”‚   â”‚   â””â”€â”€ dashboard.py         # Flask app
â”‚   â”‚
â”‚   â”œâ”€â”€ cli.py                   # Professional CLI
â”‚   â””â”€â”€ main.py                  # Entry point
â”‚
â”œâ”€â”€ ğŸ“ tests/                     # Property-based tests
â”‚   â””â”€â”€ ğŸ“ property/              # Hypothesis tests
â”‚
â”œâ”€â”€ ğŸ“„ start                      # Start the bot
â”œâ”€â”€ ğŸ“„ stop                       # Stop the bot
â”œâ”€â”€ ğŸ“„ restart                    # Restart the bot
â”œâ”€â”€ ğŸ“„ setup                      # First-time setup wizard
â”œâ”€â”€ ğŸ“„ pyproject.toml             # Project config (uv)
â””â”€â”€ ğŸ“„ README.md                  # You are here!
```

---

## ğŸ”„ Provider Failover Flow

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant B as ğŸ¤– Bot
    participant PM as ğŸ“Š ProviderManager
    participant RL as â±ï¸ RateLimiter
    participant G as âš¡ Groq
    participant O as â˜ï¸ Ollama

    U->>B: Send message
    B->>PM: Generate response
    PM->>RL: Check Groq limits
    
    alt Under 80% capacity
        RL-->>PM: âœ… OK
        PM->>G: Request
        G-->>PM: Response
    else Over 80% capacity
        RL-->>PM: âš ï¸ Proactive failover
        PM->>O: Failover request
        O-->>PM: Response
    end
    
    PM-->>B: AI Response
    B-->>U: Reply
```

---

## ğŸ›¡ï¸ Security Features

- ğŸ” **Role-based Access Control** - Admin, User, Guest permissions
- ğŸš« **Auth Failure Lockout** - Automatic lockout after failed attempts
- ğŸ”’ **PII Redaction** - Sensitive data masked in logs
- ğŸ“ **Audit Trail** - Complete activity logging
- ğŸ”‘ **API Key Protection** - Keys stored in .env, never logged

---

## ğŸ“ˆ Roadmap

- [x] Multi-provider LLM support
- [x] Smart failover with rate limiting
- [x] Web dashboard
- [x] Property-based testing
- [x] Ollama Cloud support (18+ models)
- [x] CLI setup wizard
- [x] UV-based package management
- [x] Dashboard model switching
- [ ] Voice message support
- [ ] Image generation (DALL-E/Stable Diffusion)
- [ ] WhatsApp integration
- [ ] Discord bot
- [ ] Prometheus metrics
- [ ] Docker support

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Built with these amazing tools:

- [python-telegram-bot](https://python-telegram-bot.org/) - Telegram Bot API wrapper
- [Groq](https://groq.com/) - Lightning-fast LLM inference
- [Ollama](https://ollama.ai/) - Run LLMs locally
- [Flask](https://flask.palletsprojects.com/) - Web dashboard
- [Hypothesis](https://hypothesis.readthedocs.io/) - Property-based testing
- [uv](https://docs.astral.sh/uv/) - Fast Python package manager

---

<p align="center">
  <strong>Made with ğŸ§¡ for Raspberry Pi</strong><br>
  <em>by <a href="https://github.com/sharvinzlife">@sharvinzlife</a></em>
</p>

<p align="center">
  <a href="https://github.com/sharvinzlife/OpenClaw-On-Pi/stargazers">â­ Star this repo</a> â€¢
  <a href="https://github.com/sharvinzlife/OpenClaw-On-Pi/issues">ğŸ› Report Bug</a> â€¢
  <a href="https://github.com/sharvinzlife/OpenClaw-On-Pi/issues">ğŸ’¡ Request Feature</a>
</p>
